{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to extract regular expression patterns(strg) \n",
    "## form the given string(st)\n",
    "\n",
    "## We are here using spacy style regex matcher \n",
    "\n",
    "def regex_extractor(strg,doc,st):\n",
    "  a=[]\n",
    "  expression=strg\n",
    "  for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    b=[]\n",
    "    b.append(st[start:end])\n",
    "    b.append(start)\n",
    "    b.append(end)\n",
    "    a.append(b)\n",
    "  return(a)     # returning a list of list containing txt,start_ind,end_index\n",
    "                # of the matched pattern\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## string:- Original String\n",
    "## nlp:- spacy model trained on english web data\n",
    "## nlp2:- Retrained spacy en_core_web_sm model on medical data (check final_training_data file)\n",
    "## choice:- 1 for completing removing dates fron text except year.\n",
    "##          2 for shifting the dates to protect the information without loss of valuable information(more preffered)\n",
    "\n",
    "def deidentifier(string,nlp,nlp3,choice):\n",
    "    doc=nlp((open(string)).read())        ## spacy object containg processed string i.e string after passing through default en_core_web_sm spacy model.\n",
    "    st=open((string)).read()              ## st=original string\n",
    "    \n",
    "    \n",
    "    time=['YEAR', 'YEARS', 'AGE', 'AGES', 'MONTH', 'MONTHS', 'DECADE', 'CENTURY', 'WEEK', 'DAILY', 'DAY', 'DAYS', 'NIGHT', 'NIGHTS', 'WEEKLY', 'MONTHLY', 'YEARLY']\n",
    "    address_identifier=['st','niwas','aawas','palace','road','block','gali','sector','flr','floor','path','near','oppo','bazar','house','nagar','bypass','bhawan','street','rd','sq','flat','lane','gali','circle','bldg','ave','mandal','avenue','tower','nagar','marg','chowraha','lane','heights','plaza','park','garden','gate','villa','market','apartment','chowk']\n",
    "    \n",
    "    ## regex extractor gets a regex string,doc,original string and returns a list of list containing matched pattern along with\n",
    "    ## start and end index of the pattern.\n",
    "    date_list1=regex_extractor(r\"\\D([0-9]{4}|[0-9]{1,2})(\\/|-)[0-9]{1,2}(\\/|-)([0-9]{1,2}|[0-9]{4})\\D\",doc,st)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(date_list1)):\n",
    "        date_list1[i][1]=date_list1[i][1]+1\n",
    "        date_list1[i][2]=date_list1[i][2]-1\n",
    "        date_list1[i][0]=st[date_list1[i][1]:date_list1[i][2]]\n",
    "    \n",
    "    ## If the choice is 1(remove the dates except year) this part of the program executes.\n",
    "    \n",
    "    if(choice==1):\n",
    "        for a in date_list1:\n",
    "            count=0\n",
    "            for i in range(a[1],a[1]+4):\n",
    "                if(st[i].isnumeric()):\n",
    "                    count=count+1\n",
    "            if(count==4):\n",
    "                st=st[:a[1]+4]+'X'*(a[2]-a[1]-4)+st[a[2]:] \n",
    "            else:\n",
    "                count=0\n",
    "                for j in range(a[2],a[2]-5,-1):\n",
    "                    if(st[j].isnumeric()):\n",
    "                        count=count+1\n",
    "                #print(\"count\",count)        \n",
    "                if(count==4):\n",
    "                    #print(st[a[1]:a[2]])\n",
    "                    st=st[:a[1]]+'X'*(a[2]-4-a[1])+st[a[2]-4:]\n",
    "                elif(count==3):\n",
    "                    st=st[:a[1]]+'X'*(a[2]-2-a[1])+st[a[2]-2:]\n",
    "                else:\n",
    "                    st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "                    \n",
    "                    \n",
    "    ## If the choice is 2(shifting the dates by a value)  this part of code executes and returns a list of shifted dates\n",
    "    ## along with the shift encountered.\n",
    "    shifted_datelist=[]\n",
    "    temp=0\n",
    "    k=0\n",
    "    random_val=randint(0,60)   ## getting a random number to shift all the dates by that number\n",
    "    if(choice==2):\n",
    "        for kk in range(len(date_list1)):\n",
    "            llst=[]\n",
    "            text=date_list1[kk][0]\n",
    "            front=date_list1[kk][1]+k\n",
    "            back=date_list1[kk][2]+k \n",
    "        \n",
    "        ### to shift the dates we are convering all the dates to pandas datetime and then by using pandas timedelta \n",
    "        ##  we can get the shifted dates.\n",
    "            new_date=pd.to_datetime(text, infer_datetime_format=True,errors='ignore') \n",
    "            if(type(new_date)!=str):\n",
    "               # print(new_date)\n",
    "               # print(type(new_date))\n",
    "                new_date=new_date+timedelta(days=random_val)\n",
    "               # print(str(new_date)[:-9])\n",
    "                st=st[:front]+str(new_date)[:-9]+st[back:]\n",
    "                k=k+(len(str(new_date)[:-9])-len(text))\n",
    "                llst.append(str(new_date)[:-9])\n",
    "                llst.append(front)\n",
    "                llst.append(front+len(str(new_date)[:-9]))\n",
    "                shifted_datelist.append(llst)\n",
    "               # k=k+(10-len(text))\n",
    "    \n",
    "    ## function call to extract mail,ip address, and aadhar number form the text. \n",
    "    \n",
    "    mail_list=regex_extractor(r\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*)@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\",doc,st)    \n",
    "    ip_list=regex_extractor(r\"((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\",doc,st)    \n",
    "    aadhar_list=regex_extractor(r\"(\\d{4}(\\s|\\-)\\d{4}(\\s|\\-)\\d{4})\",doc,st)\n",
    "    \n",
    "    ## replacing all the matched pattern to protect the information.\n",
    "    \n",
    "    for a in ip_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    for a in mail_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:] \n",
    "    for a in aadhar_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    ## Function call to extract urls and license plate numbers form the text\n",
    "    doc=nlp(st)\n",
    "    url_list=regex_extractor(r\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\",doc,st)    \n",
    "    license_plate_list=regex_extractor(r\"[A-Z]{2}[ -][0-9]{1,2}(?: [A-Z])?(?: [A-Z]*)? [0-9]{4}\",doc,st)  \n",
    "    for a in url_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    for a in license_plate_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    \n",
    "  ##  Hiding the extracted information to protect identity\n",
    "    \n",
    "    \n",
    "    ## Function call to extract phone numbers and fax numbers from the text.\n",
    "    doc=nlp(st)\n",
    "    phone_fax_list1=regex_extractor(r\"(?:(?:(?:(\\+)((?:[\\s.,-]*[0-9]*)*)(?:\\()?\\s?((?:[\\s.,-]*[0-9]*)+)(?:\\))?)|(?:(?:\\()?(\\+)\\s?((?:[\\s.,-]*[0-9]*)+)(?:\\))?))((?:[\\s.,-]*[0-9]+)+))\",doc,st)\n",
    "    phone_fax_list2=regex_extractor(r\"\\D(\\+91[\\-\\s]?)?[0]?(91)?[789]\\d{9}\\D\",doc,st)\n",
    "    for i in range(len(phone_fax_list2)):\n",
    "      phone_fax_list2[i][1]=phone_fax_list2[i][1]+1\n",
    "      phone_fax_list2[i][2]=phone_fax_list2[i][2]-1\n",
    "      phone_fax_list2[i][0]=st[phone_fax_list2[i][1]:phone_fax_list2[i][2]]\n",
    "    \n",
    "    phone_fax_list=[]\n",
    "    for a in phone_fax_list1:\n",
    "        phone_fax_list.append(a)\n",
    "    for a in phone_fax_list2:\n",
    "        phone_fax_list.append(a) \n",
    "    \n",
    "    for a in phone_fax_list1:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    for a in phone_fax_list2:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    \n",
    "    \n",
    "    ## Function call to extract pan number,passport number,account number,credit card number and medical record number and finally \n",
    "    ## hiding them to protect the information.\n",
    "    doc=nlp(st)\n",
    "    pan_list=regex_extractor(r\"[A-Z]{5}\\d{4}[A-Z]{1}\",doc,st)\n",
    "    passport_list=regex_extractor(r\"[A-Z]{1}\\d{7}\",doc,st)\n",
    "    account_and_serial_list=regex_extractor(r\"\\d{9,18}\",doc,st)\n",
    "    credit_card_list=regex_extractor(r\"\\d{5}(\\s|\\-)\\d{5}(\\s|\\-)\\d{5}|\\d{4}(\\s|\\-)\\d{4}(\\s|\\-)\\d{4}(\\s|\\-)\\d{4}\",doc,st)\n",
    "    \n",
    "    for a in account_and_serial_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    for a in pan_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    for a in passport_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    for a in credit_card_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    \n",
    "    doc=nlp(st)\n",
    "    medical_rep=regex_extractor('\\d{7}',doc,st)\n",
    "    ###  medical_report_no : Assuming the pattern to be 7 digit number as it is organisation dependent and can also be changed later\n",
    "    ###  accordingly.\n",
    "    \n",
    "    for a in medical_rep:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "\n",
    "   \n",
    "\n",
    "    ###  After extracting many useful information the below line of code extracts address fron the text.\n",
    "    ###  Address which are smaller than street name.\n",
    "    \n",
    "   ### For extracting addresses we use a list of common words used in addressing and match them with every elemnt in spacy \n",
    "   ### doc object and if any match is found it is inserted in addr list.\n",
    "\n",
    "    doc=nlp(st)\n",
    "    addr=[]\n",
    "    for i in doc:\n",
    "      if(len(i)>1 and '\\n' not in str(i)):\n",
    "           if(str(i).lower() in address_identifier):\n",
    "             addr.append(i)\n",
    "    ##  This addr list condains all the matched words from address identifier list.\n",
    "    ## Now it's time to remove the identified addresses after getting their position in the text.\n",
    "    \n",
    "    \n",
    "    addr_ind=[]\n",
    "    k=0\n",
    "    ll=len(st)\n",
    "    for i in addr:\n",
    "      while(1):\n",
    "        ind=st.find(str(i),k,ll)\n",
    "        if(ind==-1):\n",
    "          break\n",
    "        if(ind!=0 and ind!=ll):  \n",
    "          if((st[ind-1].isalpha() or st[ind+len(str(i))].isalpha())):\n",
    "            k=ind+len(str(i))\n",
    "          else:\n",
    "            break\n",
    "      addr_ind.append(ind)\n",
    "      k=ind+len(str(i))      \n",
    "   ## Here addr index list contains the positions of the matched words front the address identifier list.\n",
    "\n",
    "    addr_list=[]  \n",
    "    if(addr_ind!=[]):\n",
    "      temp=addr_ind[0]\n",
    "      a=[]\n",
    "      for val in addr_ind:\n",
    "            if(val-temp<20):\n",
    "              a.append(val)\n",
    "              temp=val\n",
    "            else:\n",
    "              addr_list.append(a)\n",
    "              a=[]\n",
    "              a.append(val)\n",
    "              temp=val\n",
    "      addr_list.append(a)  \n",
    "  #  print(addr_list)        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### IN ORDER TO REMOVE THE ADDRESSES THE COMPLETE WORD CONTAINING THE ADDRESS IDENTIFIER WORD(matched from the address identifier list)\n",
    "    #### HAS TO BE REMOVED.\n",
    "    ##   SO THE BELOW CODE GETS THE SPAN OF THE COMPLETE WORD IN WHICH THE ADDRESS IDENTIFIER WORD WAS USED.\n",
    "    add_list=[]\n",
    "    for a in addr_list:\n",
    "        flag=[]\n",
    "        jj=a[0]\n",
    "        while(st[jj] not in [',','\\n','.',';'] and jj!=-1):\n",
    "            jj=jj-1\n",
    "        strt=jj\n",
    "        ind1=strt\n",
    "        count=8\n",
    "        while(count and jj !=-1 and st[jj]!='\\n'):\n",
    "          if(st[jj].isdigit()):\n",
    "            strt=jj\n",
    "          jj=jj-1\n",
    "          count=count-1\n",
    "        jj=a[-1]\n",
    "        while(st[jj] not in [',','\\n','.',';'] and jj!=-1):\n",
    "          jj=jj+1\n",
    "        end=jj\n",
    "        ind2=end\n",
    "        count=7\n",
    "        while(count and jj !=ll and st[jj]!='\\n'):         # ll len(st)\n",
    "          if(st[jj].isdigit()):\n",
    "            end=jj\n",
    "          jj=jj+1\n",
    "          count=count-1\n",
    "        if((st[ind1]!='.' or st[ind2]!='.') and (ind2-ind1)<50):\n",
    "          if(st[strt]=='\\n'):\n",
    "                strt=strt+1\n",
    "          if(st[end]=='\\n'):\n",
    "                end=end-1\n",
    "          flag.append(st[strt:end+1])\n",
    "          flag.append(strt)\n",
    "          flag.append(end)\n",
    "          add_list.append(flag)    \n",
    "   ### After the above code executes it gives the complete span of the word which needs to be removed in order to hide the \n",
    "   ### address information\n",
    "    \n",
    "    for a in add_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "\n",
    "\n",
    "   ### After covering a lot of area we are now left with names,dates which could not be identified by refular expression\n",
    "   ### and age.\n",
    "      \n",
    "        \n",
    "        \n",
    "    ## to extract the dates which could not be identified by regular expression we are using en_core_web_sm spacy language model\n",
    "    ## some manipulations neede to be done in order to make the default model works according to our requirments.\n",
    "    doc3=nlp(st)\n",
    "    date_list2=[]\n",
    "    for ents in doc3.ents:\n",
    "                if(str(ents.text).count('X')<2):\n",
    "                    date=[]\n",
    "                    if(ents.label_=='DATE' and (sum([True if i not in st[ents.start_char:ents.end_char].upper() else False for i in time])==len(time)) and (ents.end_char-ents.start_char)>4 and sum(c.isdigit() for c in st[ents.start_char:ents.end_char])>=1 and sum(c.isalpha() for c in st[ents.start_char:ents.end_char])>=1):\n",
    "                        date.append(ents.text)\n",
    "                        date.append(ents.start_char)\n",
    "                        date.append(ents.end_char)\n",
    "                        date_list2.append(date)\n",
    "\n",
    "    \n",
    "    for a in date_list2:\n",
    "        count=0\n",
    "        for i in range(a[1],a[1]+4):\n",
    "            if(st[i].isnumeric()):\n",
    "                count=count+1\n",
    "        if(count==4):\n",
    "            st=st[:a[1]+4]+'X'*(a[2]-a[1]-4)+st[a[2]:]\n",
    "        else:\n",
    "            count=0\n",
    "            for j in range(a[2],a[2]-5,-1):                                ## remvoing the year so that\n",
    "                if(st[j].isnumeric()):                                     ## the year is left untouched.\n",
    "                    count=count+1                                          ##\n",
    "            if(count==4):\n",
    "                st=st[:a[1]]+'X'*(a[2]-4-a[1])+st[a[2]-4:]\n",
    "            elif(count==3):\n",
    "                st=st[:a[1]]+'X'*(a[2]-2-a[1])+st[a[2]-2:]\n",
    "            else:\n",
    "                st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:] \n",
    "    \n",
    "    date_list=[]\n",
    "    if(choice==1):\n",
    "        for a in date_list1:\n",
    "            date_list.append(a)\n",
    "    for a in date_list2:\n",
    "        date_list.append(a)\n",
    "    ### This date_list contains all the dates we extracted including the regular expression portion and spacy default model portion\n",
    "    \n",
    "   \n",
    "\n",
    "    ### Finally lets go for age.\n",
    "    ### To identify age we are again using spacy style regex matcher(phrasematcher) which takes as input patterns we want to match\n",
    "    ### and outputs the start index and end index of the matched pattern.\n",
    "    \n",
    "    ### The following line of code extracts age from text and check weather the extracted age is >89 .If yes remove it else leave as it is.\n",
    "    try:\n",
    "      age_list=[]\n",
    "      matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
    "      age_indicator=['YEAR', 'YEARS', 'Y/O', 'AGES', 'AGE', 'Y.O', 'Y.O.','AGED','AGE IS']\n",
    "      matcher.add(\"age\", None, nlp3(\"76 year old\"),nlp3(\"aged 58\"),nlp3('aged 123'),nlp3(\"54 y/o\"),nlp3(\"age is 59\"),nlp3(\"123 y/o\"), nlp3(\"ages 35\"),nlp3(\"age 45\"),nlp3(\"ages 123\"),nlp3(\"age 123\"),nlp3(\"54 years old\"),nlp3(\"124 years old\"),nlp3(\"41 y.o.\"),nlp3(\"123 y.o.\"),nlp3('113 year old'))\n",
    "      doc = nlp3(st)\n",
    "      for match_id, start, end in matcher(doc):\n",
    "          if(sum([True if i in str(doc[start:end]).upper() else False for i in age_indicator])>=1):\n",
    "              a=[]\n",
    "              for i in range(start,end):\n",
    "                  if(str(doc[i:i+1]).isnumeric()):\n",
    "                      if(int(str(doc[i:i+1]))>89):\n",
    "                          result=st.find(str(doc[start:end]))\n",
    "                          count=0\n",
    "                          for j in range(result,result+len(str(doc[start:end]))):\n",
    "                                  if(st[j:j+1].isnumeric() and count==0):\n",
    "                                      strt=j\n",
    "                                  if(st[j:j+1].isnumeric()):\n",
    "                                      count=count+1\n",
    "                          a.append(st[strt:strt+count])   \n",
    "                          a.append(strt)\n",
    "                          a.append(strt+count)\n",
    "                          age_list.append(a)\n",
    "                          st=st[:strt]+'X'*count+st[strt+count:]     \n",
    "    except:\n",
    "      None                           \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Finally lets pack all the extracted pattern in a dictionary with key as name of pattern and value as list of list contining\n",
    "    ### matached pattern ,start_index,end_index.\n",
    "    d={}\n",
    "    d['date']=date_list\n",
    "    d['mail']=mail_list\n",
    "    d['aadhar']=aadhar_list\n",
    "    d['ip']=ip_list\n",
    "    d['url']=url_list\n",
    "    d['license_plate']=license_plate_list\n",
    "    d['phone_fax']=phone_fax_list\n",
    "    d['account_serialno']=account_and_serial_list\n",
    "    d['pan']=pan_list\n",
    "    d['passport']=passport_list\n",
    "    d['credit_card']=credit_card_list\n",
    "    d['age']=age_list\n",
    "    d['address']=add_list\n",
    "    d['shifted_date']=shifted_datelist\n",
    "    d['medical_report_no']=medical_rep\n",
    "    shift=random_val \n",
    "    \n",
    "    ## Returning the processed string with all the information hidden,along with dictionary containing them and if choice was 2\n",
    "    ## the shift(by which all the dates are shifted) has to be returned as well ortherwise return shift as None(i.e for choice 1)\n",
    "    if(choice==1):\n",
    "        return(st,d,None)\n",
    "    else:\n",
    "        return(st,d,shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the required dependencies.\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "from datetime import timedelta\n",
    "import spacy\n",
    "import re\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import random\n",
    "from random import randint\n",
    "import pickle\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "## we have 2 pickle file\n",
    "## data : containg the terms assosiated with medical fields.\n",
    "## data2 : containg the names of indian cities\n",
    "## These are basically used as lookup table to reduce the error\n",
    "with open('whitelist.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open('city_state_list.pkl', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "\n",
    "## loading spacy en_core_web_sm language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "## loading a re-trained spacy language model on medical data\n",
    "nlp2=spacy.load('trained_spacy_model2')\n",
    "nlp3=English()\n",
    "\n",
    "### function takes string and choice as input and reutns the processed text along with dictionary of extracted information and shift\n",
    "def master(string,choice):\n",
    "    ## deidentifier function is called which returns processed string,dictionary and shift\n",
    "    st,dic,shift=deidentifier(string,nlp,nlp3,choice)  ## 2 for shifted dates.1 to remove them completely\n",
    "    ## the string we get here has almost all the information hidden except one last remaining part. That is name of persons and organisation.\n",
    "    ## To extract names from the processed text we are using re-trained spacy model.\n",
    "    \n",
    "    ## The below lines of code extract the names of person and org. from the processed text and hides them also.\n",
    "    tokenizer = Tokenizer(nlp3.vocab)\n",
    "    doc2=nlp2(st)\n",
    "    person_org_list=[]\n",
    "    for ents in doc2.ents:\n",
    "        if(str(ents.text).count('X')<3):\n",
    "          tokens=tokenizer(str(ents.text))\n",
    "          if(sum([True if str(i).lower() in data or '\\n' in str(i) or str(i).lower() in data2 else False for i in tokens])!=len(tokens)):\n",
    "                     a=[]\n",
    "                     a.append(ents.text)\n",
    "                     a.append(ents.start_char)\n",
    "                     a.append(ents.end_char)   \n",
    "                     person_org_list.append(a)\n",
    "    dic['person_and_org']=person_org_list\n",
    "    for a in person_org_list:\n",
    "      st=st[:a[1]]+'X'*(a[2]-a[1])+st[a[2]:]\n",
    "    \n",
    "    ## final processed string,dictionay and shift is returned.\n",
    "    return(st,dic,shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing5.txt\n"
     ]
    }
   ],
   "source": [
    "## input the name of text file to be processed.\n",
    "final_str,dic,shift=master(input(),2)  ## 2 for shifted dates.1 to remove them completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date []\n",
      "mail [['umesh.pradhan@gmail.com', 212, 235]]\n",
      "aadhar []\n",
      "ip []\n",
      "url []\n",
      "license_plate []\n",
      "phone_fax []\n",
      "account_serialno []\n",
      "pan []\n",
      "passport []\n",
      "credit_card []\n",
      "age [['96', 488, 490]]\n",
      "address [['32/1, 2nd Main Road\\n8th Block ', 26, 55], [', RD', 3879, 3882], [', RD,', 3902, 3906], ['4, Amrita Shergill Road ', 3925, 3948]]\n",
      "shifted_date [['2133-09-04', 14, 24], ['1974-02-09', 243, 253], ['2033-09-04', 281, 291], ['2033-06-13', 369, 379], ['2033-07-23', 1509, 1519], ['2033-06-26', 1533, 1543], ['2033-02-13', 1628, 1638], ['2033-06-26', 1861, 1871], ['2033-07-23', 2039, 2049], ['2033-09-04', 2088, 2098], ['2033-09-04', 3913, 3923]]\n",
      "medical_report_no []\n",
      "person_and_org [['Jayanagar', 57, 66], ['Umesh Pradhan  \\n', 181, 197], ['Kamlesh Das', 309, 320], ['Sanjana Bhatt', 3885, 3898]]\n"
     ]
    }
   ],
   "source": [
    "## extracted information.\n",
    "for items,val  in dic.items():\n",
    "    print(items,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Record date: 2133-09-04\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXX \n",
      "XXXXXXXXX \n",
      "Bangalore \n",
      "Karnataka\n",
      "560082 \n",
      "\n",
      "\n",
      "Jagruti Rehabilitation Centre, Srinagar\n",
      " \n",
      "Postop  Nutrition Assessment\n",
      "\n",
      "Patient:  XXXXXXXXXXXXXXXXEmail Address: XXXXXXXXXXXXXXXXXXXXXXX\n",
      "DOB:   1974-02-09                  \n",
      "Date:   \n",
      "2033-09-04\n",
      "\n",
      "Surgeon:   Dr.  XXXXXXXXXXX            Surgical date:    s/p gastric bypass 2033-06-13      Place: Kashmir\n",
      "\n",
      "\n",
      "S:\n",
      "\n",
      "Hx:  Pt was seen by his request with his wife.  Pt is married and 3 children ages XX, 22, and 19.  Pt lives with wife and 2 children.  Pt work as Small Equipment Mechanic.     \n",
      "\n",
      "Reported diet stage:  4\n",
      "\n",
      "Adjustments:   tried soda\n",
      "\n",
      "Issues with current diet:   chix, hamburger\n",
      "\n",
      "Food intolerance:    soda in can\n",
      "\n",
      "Nausea     \n",
      "  \n",
      "      no   \n",
      "\n",
      "Vomiting   \n",
      "  \n",
      "\n",
      "    \n",
      "yes, x1 pace, occ, \n",
      "with dry chix\n",
      "\n",
      "Diarrhea        \n",
      "    occ loose stools\n",
      "\n",
      "Constipation       occ needs more\n",
      "\n",
      "Hydration         \n",
      "  needs more\n",
      "\n",
      "Other:    \n",
      "\n",
      "24-hour dietary recall:\n",
      "\n",
      "B:        yogurt Yoplait with fruit and pb and some granola\n",
      "\n",
      "Sn:    \n",
      "\n",
      "L:       \n",
      "chix, BBQ small thigh and 2 wings, brown rice\n",
      "\n",
      "Sn:      oc carrots of fruit\n",
      "\n",
      "D:       \n",
      "1-2 eggs with shrimp and toast with marg and jelly\n",
      "\n",
      "Sn:      none\n",
      "\n",
      "Beverages:    G2 on walk, water, iced coffee with cream \n",
      "\n",
      "Supplements:   \n",
      "most days walk, 3 miles\n",
      "\n",
      "\n",
      "\n",
      "O:\n",
      "\n",
      "Age:   59 y                               Sex:   male                            \n",
      "\n",
      "Ht: \n",
      "5&#8217;7.5&#8221;                                   Wt:  \n",
      "255#                             \n",
      "\n",
      "BMI:   39.4\n",
      "\n",
      "Previous weight:           273# 2033-07-23    /   295#  2033-06-26        \n",
      "\n",
      "IBW: 138-168#              Excess Wt:  87-117#\n",
      "\n",
      "Preoperative weight: 333#  2033-02-13            Cumulative Wt Change:  down 78#\n",
      "\n",
      "PMH:  \n",
      "edema, type 2 DM, OSA with CPAP, hypercholesterolemia, HTN, cardiac myopathy, OA in knees, open chole\n",
      "\n",
      "Medications:  lantus, humalog sliding scale, Coumadin\n",
      "\n",
      "Current meds 2033-06-26:  CPAP, coumadin, ASA 81 mg, K citrate, furosemide, fluoxitine, cordarone, metoprolol, glucosamine and chondroitin, lisinopril, crestor, norvasc, pepcid\n",
      "\n",
      "Current meds 2033-07-23:  off lantus, humalog, \n",
      "\n",
      "Current meds 2033-09-04:  \n",
      "CPAP, coumadin, ASA 81 mg, K citrate, furosemide, fluoxitine, cordarone, \n",
      "metoprolol, d/c glucosamine and chondroitin, lisinopril, crestor, norvasc, pepcid\n",
      "\n",
      "Labs:  to be evaluated per surgeon, BS 110 am\n",
      "\n",
      "Prescribed diet:  stage  4\n",
      "\n",
      "Patient educational material used: Dietary Guidelines for Gastric Bypass, protein list\n",
      "\n",
      "                                                                                                            \n",
      "\n",
      "A:\n",
      "\n",
      "59 y.o. male  referred to nutrition followup for gastric bypass.\n",
      "\n",
      "\n",
      "\n",
      "Weight Assessment:  Pt weighs 255 lbs and is 68 inches tall with BMI of 39.4.     Obesity Class: 3\n",
      "\n",
      "\n",
      "\n",
      "Est. Energy Needs: \n",
      "BMR 1940 kcal/day, ~2700-3000 cal/day for weight maintenance.\n",
      "\n",
      "\n",
      "\n",
      "Dietary Assessment:\n",
      "\n",
      "\n",
      "Pt presents with h/o edema, type 2 DM, OSA with CPAP, hypercholesterolemia, HTN, cardiac myopathy, OA in knees, open chole and morbid obesity s/p gastric bypass surgery x 3 months compliant with fluid, protein and vitamin and mineral supplementation recommendations\n",
      "\n",
      "Pt to cont on stage 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Issues discussed:\n",
      "\n",
      "x  Diet stage:    4              x  Protein intake:  60 grams/day                     x  Fluid intake: &gt;64 oz/day\n",
      "\n",
      "x  Multivitamin/mineral     x  Calcium w/Vit D:  1200-1500 mg calcium         Vitamin B12\n",
      "\n",
      "x  Slowly eating and drinking, small portion sized, healthful food choices\n",
      "\n",
      "x  Protein foods, food preparation methods\n",
      "\n",
      "x  meal planning\n",
      "\n",
      "\n",
      "\n",
      "P:\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "\n",
      "Cont diet stage:  4\n",
      "\n",
      "Expected adherence:  good\n",
      "\n",
      "Goals:  &gt;64 ounces fluid/day, &gt;60 grams protein/day\n",
      "\n",
      "Cont Multivitamin/mineral daily, cont 1200-1500 \n",
      "mg calcium with added vitamin D daily \n",
      "\n",
      "Use protein list as guide\n",
      "\n",
      "Increase food variety and consistency slowly\n",
      "\n",
      "Cont current activity, increase as able\n",
      "\n",
      "Call or email with any questions or problems\n",
      "\n",
      "\n",
      "RTC 3 months postop surgXXXD\n",
      "\n",
      "XXXXXXXXXXXXX, MSXXXX, LDN\n",
      "\n",
      "2033-09-04\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXXXXX \n",
      "New Delhi\n",
      "110003 \n",
      "INDIA \n"
     ]
    }
   ],
   "source": [
    "## final processed string\n",
    "print(final_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"testing5_deidentified.txt\", \"w\")\n",
    "f.write(final_str)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
